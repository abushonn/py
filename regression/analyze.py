import os
import re
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix
import subprocess
from shutil import copyfile

import xlsx_editing
import config_utils

def calc_precision_recall(df, expected_colname, detected_colname, intent_name):
    '''
    For the specified intent.
    :param df_detail: 
    :param expected_colname: 
    :param detected_col_name: 
    :param selected_intent_name: 
    :return: 
    '''

    N = df.shape[0] # number of examples

    intents = pd.unique(df[[expected_colname, detected_colname]].values.ravel())
    # Generate confusion matrix and calculate stats
    conf_mat = confusion_matrix(df[expected_colname], df[detected_colname], labels=intents)
    TP = np.diag(conf_mat)
    FP = np.sum(conf_mat, axis=0) - TP
    FN = np.sum(conf_mat, axis=1) - TP
    TP_FP = TP + FP
    TP_FN = TP + FN
    df_intent_stats = pd.DataFrame({'TP': TP, 'TP_FP': TP_FP, 'TP_FN': TP_FN,'intent': intents})
    df_selected = df_intent_stats[df_intent_stats['intent'] == intent_name]
    intent_tp = df_selected.iloc[0]['TP']
    intent_tp_fp = df_selected.iloc[0]['TP_FP']
    intent_tp_fn = df_selected.iloc[0]['TP_FN']

    precision = intent_tp / intent_tp_fp
    recall = intent_tp / intent_tp_fn
    overall_accuracy = TP.sum() / N

    return precision, recall, overall_accuracy

def generate_stat_summary_str(df_stats):
    '''
    return df with columns ['statistic', 'summary']. The summary column has format: median% [min-max%]
    :param df_stats: 
    :return: pandas.DataFrame
    '''
    df_summary = pd.DataFrame(columns = ['statistic', 'summary'])
    ser_median = df_stats.median()
    ser_min = df_stats.min()
    ser_max = df_stats.max()
    for stat in list(df_stats):
        median_str = "{:.0%}".format(ser_median[stat])
        min_str = "{:.0%}".format(ser_min[stat])
        max_str = "{:.0%}".format(ser_max[stat])
        summary_str = median_str + ' [' + min_str + '-' + max_str + ']'
        df_summary = df_summary.append({'statistic': stat, 'summary': summary_str}, ignore_index = True)
    return df_summary

def combine_wcslp_results(config):
    '''
    Extract stats (precision, recall, overall_accuracy) from each of the fold results.
    Write results table to a separate file, and generate statis summary string: median% [min-max%]
    combine details from all folds into one file. 
    :param dirpath: path to dir containing k-fold cross-val result files (generated by eval.py)
    :param out_file_name: String, name of CSV file to be written (under dirpath) 
    :return:
    '''

    dirpath = config['results_dirname']
    filename_ptrn = config['wcslp']['output_filename'].replace('.xlsx', '_(\d).xlsx')
    precision_col_name = 'precision ' + config['analysis']['selected_intent_name']
    recall_col_name = 'recall ' + config['analysis']['selected_intent_name']
    accuracy_col_name = 'overall accuracy'

    df_stats = pd.DataFrame(columns = [precision_col_name, recall_col_name, accuracy_col_name])
    df_all_folds = pd.DataFrame() # concatenation
    for filename in os.listdir(dirpath):
        m = re.match(filename_ptrn, filename)
        if m:
            fold_num = m.group(1)
            filepath = os.path.join(dirpath, filename)
            # read detailed results (example-level)
            df = xlsx_editing.read_sheet_to_df(filepath, config['wcslp']['output_file_detail_sheet_name'])
            # False Negatives (top intent confidence is below threshold): set detected intent to 'Irrelevant'
            df.loc[df[config['wcslp']['output_top_result_colname']] == 'False Negative', config['wcslp']['output_detected_intent_colname']] = 'Irrelevant'
            # add a 'fold_num' column
            df['fold_num'] = fold_num
            # concateante current fold to previous
            df_all_folds = pd.concat([df_all_folds, df], ignore_index=True)

            # calculate and save stats
            precision, recall, overall_accuracy = calc_precision_recall(
                df,
                config['wcslp']['output_expected_intent_colname'],
                config['wcslp']['output_detected_intent_colname'],
                config['analysis']['selected_intent_name'])
            df_stats.at[int(fold_num), precision_col_name] = precision
            df_stats.at[int(fold_num), recall_col_name] = recall
            df_stats.at[int(fold_num), accuracy_col_name] = overall_accuracy

    # generate statistic summary strings
    df_summary = generate_stat_summary_str(df_stats)

    # write
    out_dir = os.path.join(config['results_dirname'], config['analysis']['selected_intent_name'])
    print('out_dir:  ' + out_dir)
    if not os.path.exists(out_dir):
        os.makedirs(out_dir)

    df_stats.to_csv(os.path.join(out_dir, config['analysis']['stats_fname']), index_label = 'fold_num')
    df_all_folds.to_csv(os.path.join(out_dir, config['analysis']['details_fname']), index = False)
    df_summary.to_csv(os.path.join(out_dir, config['analysis']['summary_fname']), index = False)

    return df_stats, df_all_folds

def prepare_wa_improve_input_file(df_wcslp, config):
    '''
    Write in Excel template the necessary information for intent analysis using WA Effectiveness notebook. 
    :param df_wcslp: all folds combined in WCS-LP format 
    :return: 
    '''

    dirname = os.path.join(config['wa_notebook']['dirname'], config['wa_notebook']['data_subdir_name'])
    # read Excel template
    df = xlsx_editing.read_sheet_to_df(os.path.join(dirname, config['wa_notebook']['template_fname']), config['wa_notebook']['template_sheet_name'])
    # populate
    df['Utterance Text'] = df_wcslp['Question Text']
    df['Detected top intent'] = df_wcslp['Intent 1']
    df['Wrong intent? If yes, put the correct intent. Otherwise leave it blank'] = \
        df_wcslp['Expected Intent'].where(df_wcslp['Intent 1'] != df_wcslp['Expected Intent'])

    # write file
    xlsx_editing.write_df_to_sheet(df, os.path.join(dirname, config['wa_notebook']['data_fname']), config['wa_notebook']['template_sheet_name'])

def run_wa_improve_notebook(config):
    '''
    execute WA Effectiveness notebook as a subprocess, and copy output files to results dir.
    :return:
    '''

    cwd = os.getcwd()
    wa_notebook_wd = os.path.join(cwd, config['wa_notebook']['dirname'])

    #converts jupiter notebook to html
    proc = subprocess.run(
        ['jupyter', 'nbconvert', '--to=html', '--ExecutePreprocessor.enabled=True',
         config['wa_notebook']['notebook_fname']], cwd = wa_notebook_wd)
    if proc.returncode:
        print('ERROR running jupyter notebook ' + config['wa_notebook']['notebook_fname'] + '\nreturn code: ' + str(proc.returncode))
        exit(1)

    # copy output files to results dir
    for fname in config['wa_notebook']['result_fnames']:
        src = os.path.join(config['wa_notebook']['dirname'], fname)
        dst = os.path.join(config['results_dirname'], fname)
        copyfile(src, dst)


def run(config):
    '''
    execute analysis 
    :param config: 
    :return: 
    '''
    df_stats, df_all_folds = combine_wcslp_results(config)
    prepare_wa_improve_input_file(df_all_folds, config)
    run_wa_improve_notebook(config)


if __name__ == '__main__':

    config_file_name = 'config.json'
    config = config_utils.read_config(config_file_name)

    df_stats, df_all_folds = combine_wcslp_results(config)
    prepare_wa_improve_input_file(df_all_folds, config)
    run_wa_improve_notebook(config)
